combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
combined
pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=len, fill=ramking)) +
geom_bar(stat="identity", position=position_dodge())+
geom_text(aes(label=len), vjust=1.6, color="white",
position = position_dodge(0.9), size=3.5)+
scale_fill_brewer(palette="Paired")+
theme_minimal()
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=len, fill=ramking)) +
geom_bar(stat="identity", position=position_dodge())+
geom_text(aes(label=len), vjust=1.6, color="white",
position = position_dodge(0.9), size=3.5)+
scale_fill_brewer(palette="Paired")+
theme_minimal()
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity", position=position_dodge())+
geom_text(aes(label=value), vjust=1.6, color="white",
position = position_dodge(0.9), size=3.5)+
scale_fill_brewer(palette="Paired")+
theme_minimal()
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs()
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "sum of all means of Clearance, Content, Visualization and Profesional ranking methods",
)
result_ranking <- read_csv("../data/data_change.csv")
result_ranking
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
longer_combined
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "sum of all means of Clearance, Content, Visualization and Profesional ranking methods",
y = "mean of total ranking")
result_ranking <- read_csv("../data/data_change.csv")
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "sum of all means of Clearance, Content, Visualization and Profesional ranking methods",
y = "mean of total ranking")
result_ranking <- read_csv("../data/data_change.csv")
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "mean of total rank devided to ranking categorys",
y = "mean of total ranking")
result_ranking <- read_csv("../data/data_change.csv")
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "mean of Mammals total rank devided to ranking categorys",
y = "mean of total ranking")
result_ranking <- read_csv("../data/data_change.csv")
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
combined
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "mean of Mammals total rank devided to ranking categorys",
y = "mean of total ranking")
opts_chunk$set(echo=FALSE) # hide source code in the document
opts_chunk$set(echo=FALSE) # hide source code in the document
opts_chunk$set(echo=FALSE) # hide source code in the document
library(knitr)
library(tidyverse)
library(broom)
library(htmltools)
library(readr)
library(robotstxt)
library(xml2)
library(rvest)
library(ggplot2)
library(dplyr)
opts_chunk$set(echo=FALSE) # hide source code in the document
cat(readLines('../data/README.md'), sep = '\n')
result_num_set <- read_csv("../data/result_num_chaneged.csv")
ggplot(data = result_num_set, mapping = aes(x =  factor(language, level = c('english', 'russian', 'arabic','hebrew')), y = result_num )) +
geom_point() +
scale_y_continuous(trans = 'log10') +
theme_light()+
labs(x = "language",
y = "number of search result",
title = "Mammal search - number of result per language",
subtitle = "logaritmic scale")
result_ranking <- read_csv("../data/data_change.csv")
Clearance_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Clearance definition"), list("Clearance definition" = mean))
Content_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Content"), list("Content" = mean))
Visualization_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Visualization"), list("Visualization" = mean))
Profesional_mean <- result_ranking %>%
group_by(language) %>%
summarise_at(vars("Profesional looking site"), list("Profesional looking site" = mean))
advertize <- result_ranking %>%
group_by(language) %>%
count(adds)
advertize <- advertize %>%
group_by(language) %>%
summarise(sites_with_adds = sum(n[adds =="Yes"])/sum(n))
combined <- Clearance_mean %>%
inner_join(Content_mean) %>%
inner_join(Visualization_mean) %>%
inner_join(Profesional_mean) %>%
inner_join(advertize)
combined
longer_combined <- pivot_longer(combined,
cols = c("Clearance definition", Content, Visualization,"Profesional looking site"),
names_to = "ramking")
ggplot(data=longer_combined, aes(x=language, y=value, fill=ramking)) +
geom_bar(stat="identity")+
scale_fill_brewer(palette="Paired")+
theme_minimal()+
labs(title = "mean of Mammals total rank devided to ranking categorys",
y = "mean of total ranking")
search_page_scrape <- function(html_path, language, topic){
# scraping google search html file and return data frame with the values (topic, language, result url, result title, result summery)
rawHTML <- read_html(html_path)
if(language == "english" || language == "russian"){
urls <- rawHTML %>%
html_nodes(".tjvcx") %>%
html_text()
urls <- urls[seq(1, length(urls), 2)]
urls <- gsub("\\ .*", "", urls)
}
else{
urls <- rawHTML %>%
html_nodes(".tjvcx > span:nth-child(1)") %>%
html_text()
urls <- urls[seq(1, length(urls), 2)]
}
titles <- rawHTML %>%
html_nodes(".DKV0Md") %>%
html_text()
summery <- rawHTML %>%
html_nodes(".lyLwlc") %>%
html_text()
fsummery <- rawHTML %>%
html_nodes(".hgKElc") %>%
html_text()
fsummery
summery <- c(fsummery, summery)
typeof(summery)
google_search <- tibble(
topic = topic,
language = language,
url = urls,
title = titles,
summery = summery
)
return(google_search)
}
all_scraper <- function(){
# reads a csv file contain (term, language, path to html) and write 2 csv files: first page results and number of result for each term and language
exceldata = read.csv("../data/html_classefire.csv")
df <- data.frame(exceldata)
topics <- df$topic
languages <- df$language
paths <- df$path
new_df <- search_page_scrape(paths[1], languages[1], topics[1])
result_df <- scraping_number_of_result(paths[1], languages[1], topics[1])
for(i in 2:length(topics)){
new_df <- rbind(new_df, search_page_scrape(paths[i], languages[i], topics[i]))
result_df <- rbind(result_df, scraping_number_of_result(paths[i], languages[i], topics[i]))
}
write.csv(new_df, "../data/data.csv", row.names=TRUE)
write.csv(result_df, "../data/result_num.csv", row.names=TRUE)
}
scraping_number_of_result <- function(html_path, language, topic){
# return number of results for Google search html file
rawHTML <- read_html(html_path)
result_num <- rawHTML %>%
html_node("#result-stats") %>%
html_text() %>%
str_extract("[0-9]{1,3}( [0-9]{3})+|[0-9]{1,3}(,[0-9]{3})+") %>%
str_remove_all(",") %>%
str_remove_all(" ") %>%
as.numeric()
result_set <- tibble(
topic = topic,
language = language,
result_num = result_num)
}
all_scraper()
cat(readLines('../data/README.md'), sep = '\n')
cat(readLines('../data/README.md'), sep = '\n')
